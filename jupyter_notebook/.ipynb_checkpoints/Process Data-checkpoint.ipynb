{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import neighbors, datasets\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dat = ['australian.dat','bupa.dat','glass.dat']\n",
    "cv_filename = ['cv_australian.mat','cv_bupa.mat','cv_glass.mat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN,Naive Bayes,LogisticRegression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ LogisticRegression(random_state=0),GaussianNB(),neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_models(models,features_train,targets_train,features_test):\n",
    "    meta_proba = np.zeros((len(models) * 2, features_test.shape[0]))\n",
    "    for i in range(len(models)):\n",
    "        learner = models[i]\n",
    "        learner.fit(features_train,targets_train)\n",
    "        predictions_proba = learner.predict_proba(features_test)\n",
    "        meta_proba[2*i][:] = predictions_proba.T[0]\n",
    "        meta_proba[2*i + 1][:] = predictions_proba.T[1]\n",
    "    meta_proba = meta_proba.transpose()\n",
    "    return meta_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caculate Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_sum_product(matrix1, matrix2, matrix3):\n",
    "    #Combining Algorithms use Sum Rules\n",
    "    combining_sum_rule = matrix1 + matrix2 + matrix3\n",
    "    combining_sum_rule = combining_sum_rule * 1/3   #Mean elements in matrix\n",
    "    #Combining algorithms PRODUCT RULES\n",
    "    combining_product_rule =  matrix1 * matrix2 * matrix3\n",
    "    return combining_sum_rule,combining_product_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining algorithms MIN RULES\n",
    "#Function compare element row in matrix => Min value \n",
    "def min_element(value1, value2, value3):\n",
    "    min_value = min([value1, value2, value3])\n",
    "    return min_value \n",
    "\n",
    "def row_in_matrix(i,matrix_1, matrix_2, matrix_3):\n",
    "    min_value_class1 = min_element(value1=matrix_1[i][0], value2=matrix_2[i][0], value3= matrix_3[i][0])\n",
    "    min_value_class2 = min_element(value1=matrix_1[i][1], value2=matrix_2[i][1], value3= matrix_3[i][1])\n",
    "    return min_value_class1, min_value_class2\n",
    "    \n",
    "def min_rule(matrix_1, matrix_2, matrix_3):\n",
    "    combining_min_rule = np.zeros((matrix_1.shape))\n",
    "    \n",
    "    #Store variables to combining matrix\n",
    "    for i in range(len(matrix_1)):\n",
    "        combining_min_rule[i] = row_in_matrix(i, matrix_1=matrix_1,\n",
    "                                         matrix_2=matrix_2,matrix_3=matrix_3)\n",
    "    return combining_min_rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining algorithms MAX RULES\n",
    "#Create variables to store combining matrix\n",
    "def max_element(value1, value2, value3):\n",
    "        max_value = max([value1, value2, value3])\n",
    "        return max_value \n",
    "#Function compare element row in matrix => Max value \n",
    "def row_in_matrix(i,matrix_1, matrix_2, matrix_3):\n",
    "        max_value_class1 = max_element(value1=matrix_1[i][0], value2=matrix_2[i][0], value3= matrix_3[i][0])\n",
    "        max_value_class2 = max_element(value1=matrix_1[i][1], value2=matrix_2[i][1], value3= matrix_3[i][1])\n",
    "        return max_value_class1, max_value_class2\n",
    "    \n",
    "def max_rule(matrix_1, matrix_2, matrix_3):\n",
    "    combining_max_rule = np.zeros((matrix_1.shape))\n",
    "    \n",
    "    #Store variables to combining matrix\n",
    "    for i in range(len(matrix_1)):\n",
    "        combining_max_rule[i] = row_in_matrix(i, matrix_1=matrix_1,\n",
    "                                             matrix_2=matrix_2,matrix_3=matrix_3)\n",
    "    return combining_max_rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(combining_matrix):\n",
    "    targets_combining_algorithm = []\n",
    "    for row in combining_matrix:\n",
    "        result = 1 if row[0] > row[1] else 2\n",
    "        targets_combining_algorithm.append(result)\n",
    "    targets_combining_algorithm = np.asarray(targets_combining_algorithm)\n",
    "    return targets_combining_algorithm\n",
    "    \n",
    "def error_combining_rule(target_combining_rule, target_test):\n",
    "    boolen_result = []\n",
    "    for i in range(len(target_test)):\n",
    "        result = 1 if target_combining_rule[i] != target_test[i] else 0\n",
    "        boolen_result.append(result)\n",
    "    mean_combining_rule = statistics.mean(boolen_result)\n",
    "#     variance_combining_rule = statistics.variance(boolen_result)\n",
    "    return mean_combining_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrErrSum = []\n",
    "arrErrProd = []\n",
    "arrErrMax= []\n",
    "arrErrMin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_dat(filename_dat):\n",
    "    samples = []\n",
    "    data_set = [i.strip().split() for i in open(\"../data/\" + filename_dat).readlines()] \n",
    "    for sample in data_set:\n",
    "        res = ast.literal_eval(sample[0])\n",
    "        sample = list(res)\n",
    "        samples.append(sample)\n",
    "    samples = np.asarray(samples)\n",
    "    return samples\n",
    "\n",
    "def process_cv_filename(cv_file):\n",
    "    cv_mat = scipy.io.loadmat('../data/' + cv_file)\n",
    "    return cv_mat['cv']\n",
    "\n",
    "def split_train_test_by_id(data,cv_file, niters, nfolds):\n",
    "    for i in range(niters):\n",
    "        for j in range(nfolds):\n",
    "            train_index = []\n",
    "            cv_test = process_cv_filename(cv_file)\n",
    "            test_index = cv_test[0][i*nfolds + j]\n",
    "            test_index = np.concatenate(([i-1 for i in test_index]))\n",
    "#             print(\"LOOP:\",i*nfolds + j)\n",
    "            train_index.append([i for i in range(len(data)) if i not in test_index]) \n",
    "            train_index = np.asarray(train_index[0])\n",
    "#             print(data[train_index])\n",
    "#             print(data[test_index])\n",
    "            meta_proba = training_models(models,features_train=data[train_index][:,0:data.shape[1] - 1],\n",
    "                               targets_train=data[train_index][:,-1], features_test=data[test_index][:,0:data.shape[1] - 1])\n",
    "            predict_lr_proba = meta_proba[:,0:2]\n",
    "            predict_gnb_proba = meta_proba[:,2:4]\n",
    "            predict_knn_proba = meta_proba[:,4:6]\n",
    "            #Caculate Mean and Variance by Sum Rules:\n",
    "            combining_sum_rule,combining_product_rule = combining_sum_product(predict_lr_proba,predict_gnb_proba,\n",
    "                                                                             predict_knn_proba)\n",
    "            targets_combining_sum_rule = target(combining_sum_rule)\n",
    "            mean_combining_sum_rule = error_combining_rule(targets_combining_sum_rule, data[test_index][:,-1] )\n",
    "            arrErrSum.append(mean_combining_sum_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Product Rules:\n",
    "            targets_combining_product_rule = target(combining_product_rule)\n",
    "            mean_combining_product_rule = error_combining_rule(targets_combining_product_rule, data[test_index][:,-1] )\n",
    "            arrErrProd.append(mean_combining_product_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Min Rules:\n",
    "            combining_min_rule = min_rule(predict_lr_proba,predict_gnb_proba,predict_knn_proba)\n",
    "            targets_combining_min_rule = target(combining_min_rule)\n",
    "            mean_combining_min_rule = error_combining_rule(targets_combining_min_rule, data[test_index][:,-1] )\n",
    "            arrErrMin.append(mean_combining_min_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Max Rules:\n",
    "            combining_max_rule = max_rule(predict_lr_proba,predict_gnb_proba,predict_knn_proba)\n",
    "            targets_combining_max_rule = target(combining_max_rule)\n",
    "            mean_combining_max_rule = error_combining_rule(targets_combining_max_rule, data[test_index][:,-1] )\n",
    "            arrErrMax.append(mean_combining_max_rule)\n",
    "    #Caculate mean and variance Total Sum Rule\n",
    "    mean_sum = statistics.mean(arrErrSum)\n",
    "    variance_sum = statistics.variance(arrErrSum)\n",
    "    #Caculate mean and variance Total Product Rule\n",
    "    mean_product = statistics.mean(arrErrProd)\n",
    "    variance_product = statistics.variance(arrErrProd)\n",
    "    #Caculate mean and variance Total Min Rule\n",
    "    mean_min = statistics.mean(arrErrMin)\n",
    "    variance_min = statistics.variance(arrErrMin)\n",
    "    #Caculate mean and variance Total Max Rule\n",
    "    mean_max = statistics.mean(arrErrMax)\n",
    "    variance_max = statistics.variance(arrErrMax)\n",
    "    \n",
    "    pickle_file = {'Dataset':cv_file,'arrErrSum':arrErrSum,'arrErrProd':arrErrProd,\n",
    "                   'arrErrMin':arrErrMin,'arrErrMax':arrErrMax}\n",
    "    pickle_out = open(\"dict_{}.pickle\".format(cv_file),\"wb\")\n",
    "    pickle.dump(pickle_file, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_dat)):\n",
    "    data = process_data_dat(data_dat[i])\n",
    "    split_train_test_by_id(data,cv_filename[i],niters=3,nfolds=10)\n",
    "    pickle_in = open(\"dict_cv_australian.mat.pickle\",\"rb\")\n",
    "    example_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"dict_cv_australian.mat.pickle\",\"rb\")\n",
    "example_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>arrErrSum</th>\n",
       "      <th>arrErrProd</th>\n",
       "      <th>arrErrMin</th>\n",
       "      <th>arrErrMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.159420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.318841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.246377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.159420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.275362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.289855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.144928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.202899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  arrErrSum  arrErrProd  arrErrMin  arrErrMax\n",
       "0   cv_australian.mat   0.144928    0.144928   0.159420   0.159420\n",
       "1   cv_australian.mat   0.318841    0.318841   0.318841   0.318841\n",
       "2   cv_australian.mat   0.188406    0.188406   0.202899   0.202899\n",
       "3   cv_australian.mat   0.173913    0.173913   0.173913   0.173913\n",
       "4   cv_australian.mat   0.173913    0.188406   0.188406   0.188406\n",
       "5   cv_australian.mat   0.188406    0.188406   0.188406   0.188406\n",
       "6   cv_australian.mat   0.289855    0.289855   0.304348   0.304348\n",
       "7   cv_australian.mat   0.159420    0.159420   0.173913   0.173913\n",
       "8   cv_australian.mat   0.159420    0.173913   0.173913   0.173913\n",
       "9   cv_australian.mat   0.231884    0.231884   0.231884   0.231884\n",
       "10  cv_australian.mat   0.173913    0.173913   0.173913   0.173913\n",
       "11  cv_australian.mat   0.275362    0.304348   0.304348   0.304348\n",
       "12  cv_australian.mat   0.217391    0.217391   0.217391   0.217391\n",
       "13  cv_australian.mat   0.231884    0.246377   0.260870   0.260870\n",
       "14  cv_australian.mat   0.260870    0.260870   0.260870   0.260870\n",
       "15  cv_australian.mat   0.246377    0.246377   0.231884   0.231884\n",
       "16  cv_australian.mat   0.217391    0.217391   0.231884   0.231884\n",
       "17  cv_australian.mat   0.246377    0.246377   0.246377   0.246377\n",
       "18  cv_australian.mat   0.173913    0.173913   0.188406   0.188406\n",
       "19  cv_australian.mat   0.188406    0.188406   0.188406   0.188406\n",
       "20  cv_australian.mat   0.173913    0.173913   0.159420   0.159420\n",
       "21  cv_australian.mat   0.260870    0.260870   0.275362   0.275362\n",
       "22  cv_australian.mat   0.246377    0.246377   0.289855   0.289855\n",
       "23  cv_australian.mat   0.173913    0.202899   0.202899   0.202899\n",
       "24  cv_australian.mat   0.188406    0.188406   0.173913   0.173913\n",
       "25  cv_australian.mat   0.217391    0.217391   0.217391   0.217391\n",
       "26  cv_australian.mat   0.159420    0.159420   0.144928   0.144928\n",
       "27  cv_australian.mat   0.217391    0.231884   0.231884   0.231884\n",
       "28  cv_australian.mat   0.231884    0.231884   0.231884   0.231884\n",
       "29  cv_australian.mat   0.202899    0.202899   0.202899   0.202899"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame.from_dict(example_dict)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
