{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import neighbors, datasets\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dat = ['australian.dat','bupa.dat','glass.dat']\n",
    "cv_filename = ['cv_australian.mat','cv_bupa.mat','cv_glass.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN,Naive Bayes,LogisticRegression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ LogisticRegression(random_state=0),GaussianNB(),neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_models(models,features_train,targets_train,features_test):\n",
    "    meta_proba = np.zeros((len(models) * 2, features_test.shape[0]))\n",
    "    for i in range(len(models)):\n",
    "        learner = models[i]\n",
    "        learner.fit(features_train,targets_train)\n",
    "        predictions_proba = learner.predict_proba(features_test)\n",
    "        meta_proba[2*i][:] = predictions_proba.T[0]\n",
    "        meta_proba[2*i + 1][:] = predictions_proba.T[1]\n",
    "    meta_proba = meta_proba.transpose()\n",
    "    return meta_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caculate Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_sum_product(matrix1, matrix2, matrix3):\n",
    "    #Combining Algorithms use Sum Rules\n",
    "    combining_sum_rule = matrix1 + matrix2 + matrix3\n",
    "    combining_sum_rule = combining_sum_rule * 1/3   #Mean elements in matrix\n",
    "    #Combining algorithms PRODUCT RULES\n",
    "    combining_product_rule =  matrix1 * matrix2 * matrix3 * 1/3\n",
    "    return combining_sum_rule,combining_product_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining algorithms MIN RULES\n",
    "#Function compare element row in matrix => Min value \n",
    "def min_element(value1, value2, value3):\n",
    "    min_value = min([value1, value2, value3])\n",
    "    return min_value \n",
    "\n",
    "def row_in_matrix(i,matrix_1, matrix_2, matrix_3):\n",
    "    min_value_class1 = min_element(value1=matrix_1[i][0], value2=matrix_2[i][0], value3= matrix_3[i][0])\n",
    "    min_value_class2 = min_element(value1=matrix_1[i][1], value2=matrix_2[i][1], value3= matrix_3[i][1])\n",
    "    return min_value_class1, min_value_class2\n",
    "    \n",
    "def min_rule(matrix_1, matrix_2, matrix_3):\n",
    "    combining_min_rule = np.zeros((matrix_1.shape))\n",
    "    \n",
    "    #Store variables to combining matrix\n",
    "    for i in range(len(matrix_1)):\n",
    "        combining_min_rule[i] = row_in_matrix(i, matrix_1=matrix_1,\n",
    "                                         matrix_2=matrix_2,matrix_3=matrix_3)\n",
    "    return combining_min_rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining algorithms MAX RULES\n",
    "#Create variables to store combining matrix\n",
    "def max_element(value1, value2, value3):\n",
    "        max_value = max([value1, value2, value3])\n",
    "        return max_value \n",
    "#Function compare element row in matrix => Max value \n",
    "def row_in_matrix(i,matrix_1, matrix_2, matrix_3):\n",
    "        max_value_class1 = max_element(value1=matrix_1[i][0], value2=matrix_2[i][0], value3= matrix_3[i][0])\n",
    "        max_value_class2 = max_element(value1=matrix_1[i][1], value2=matrix_2[i][1], value3= matrix_3[i][1])\n",
    "        return max_value_class1, max_value_class2\n",
    "    \n",
    "def max_rule(matrix_1, matrix_2, matrix_3):\n",
    "    combining_max_rule = np.zeros((matrix_1.shape))\n",
    "    \n",
    "    #Store variables to combining matrix\n",
    "    for i in range(len(matrix_1)):\n",
    "        combining_max_rule[i] = row_in_matrix(i, matrix_1=matrix_1,\n",
    "                                             matrix_2=matrix_2,matrix_3=matrix_3)\n",
    "    return combining_max_rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(combining_matrix):\n",
    "    targets_combining_algorithm = []\n",
    "    for row in combining_matrix:\n",
    "        result = 1 if row[0] > row[1] else 2\n",
    "        targets_combining_algorithm.append(result)\n",
    "    targets_combining_algorithm = np.asarray(targets_combining_algorithm)\n",
    "    return targets_combining_algorithm\n",
    "    \n",
    "def error_combining_rule(target_combining_rule, target_test):\n",
    "    boolen_result = []\n",
    "    for i in range(len(target_test)):\n",
    "        result = 1 if target_combining_rule[i] != target_test[i] else 0\n",
    "        boolen_result.append(result)\n",
    "    mean_combining_rule = statistics.mean(boolen_result)\n",
    "#     variance_combining_rule = statistics.variance(boolen_result)\n",
    "    return mean_combining_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_dat(filename_dat):\n",
    "    samples = []\n",
    "    data_set = [i.strip().split() for i in open(\"../data/\" + filename_dat).readlines()] \n",
    "    for sample in data_set:\n",
    "        res = ast.literal_eval(sample[0])\n",
    "        sample = list(res)\n",
    "        samples.append(sample)\n",
    "    samples = np.asarray(samples)\n",
    "    return samples\n",
    "\n",
    "def process_cv_filename(cv_file):\n",
    "    cv_mat = scipy.io.loadmat('../data/' + cv_file)\n",
    "    return cv_mat['cv']\n",
    "\n",
    "def split_train_test_by_id(data,cv_file, niters, nfolds):\n",
    "    arrErrSum = []\n",
    "    arrErrProd = []\n",
    "    arrErrMax= []\n",
    "    arrErrMin = []\n",
    "    for i in range(niters):\n",
    "        for j in range(nfolds):\n",
    "            train_index = []\n",
    "            cv_test = process_cv_filename(cv_file)\n",
    "            test_index = cv_test[0][i*nfolds + j]\n",
    "            test_index = np.concatenate(([i-1 for i in test_index]))\n",
    "#             print(\"LOOP:\",i*nfolds + j)\n",
    "            train_index.append([i for i in range(len(data)) if i not in test_index]) \n",
    "            train_index = np.asarray(train_index[0])\n",
    "#             print(data[train_index])\n",
    "#             print(data[test_index])\n",
    "            meta_proba = training_models(models,features_train=data[train_index][:,0:data.shape[1] - 1],\n",
    "                               targets_train=data[train_index][:,-1], features_test=data[test_index][:,0:data.shape[1] - 1])\n",
    "            predict_lr_proba = meta_proba[:,0:2]\n",
    "            predict_gnb_proba = meta_proba[:,2:4]\n",
    "            predict_knn_proba = meta_proba[:,4:6]\n",
    "            #Caculate Mean and Variance by Sum Rules:\n",
    "            combining_sum_rule,combining_product_rule = combining_sum_product(predict_lr_proba,predict_gnb_proba,\n",
    "                                                                             predict_knn_proba)\n",
    "            targets_combining_sum_rule = target(combining_sum_rule)\n",
    "            mean_combining_sum_rule = error_combining_rule(targets_combining_sum_rule, data[test_index][:,-1] )\n",
    "            arrErrSum.append(mean_combining_sum_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Product Rules:\n",
    "            targets_combining_product_rule = target(combining_product_rule)\n",
    "            mean_combining_product_rule = error_combining_rule(targets_combining_product_rule, data[test_index][:,-1] )\n",
    "            arrErrProd.append(mean_combining_product_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Min Rules:\n",
    "            combining_min_rule = min_rule(predict_lr_proba,predict_gnb_proba,predict_knn_proba)\n",
    "            targets_combining_min_rule = target(combining_min_rule)\n",
    "            mean_combining_min_rule = error_combining_rule(targets_combining_min_rule, data[test_index][:,-1] )\n",
    "            arrErrMin.append(mean_combining_min_rule)\n",
    "            \n",
    "            #Caculate Mean and Variance by Max Rules:\n",
    "            combining_max_rule = max_rule(predict_lr_proba,predict_gnb_proba,predict_knn_proba)\n",
    "            targets_combining_max_rule = target(combining_max_rule)\n",
    "            mean_combining_max_rule = error_combining_rule(targets_combining_max_rule, data[test_index][:,-1] )\n",
    "            arrErrMax.append(mean_combining_max_rule)\n",
    "#     #Caculate mean and variance Total Sum Rule\n",
    "#     mean_sum = statistics.mean(arrErrSum)\n",
    "#     variance_sum = statistics.variance(arrErrSum)\n",
    "#     #Caculate mean and variance Total Product Rule\n",
    "#     mean_product = statistics.mean(arrErrProd)\n",
    "#     variance_product = statistics.variance(arrErrProd)\n",
    "#     #Caculate mean and variance Total Min Rule\n",
    "#     mean_min = statistics.mean(arrErrMin)\n",
    "#     variance_min = statistics.variance(arrErrMin)\n",
    "#     #Caculate mean and variance Total Max Rule\n",
    "#     mean_max = statistics.mean(arrErrMax)\n",
    "#     variance_max = statistics.variance(arrErrMax)\n",
    "    \n",
    "    pickle_file = {'Dataset':cv_file,'arrErrSum':arrErrSum,'arrErrProd':arrErrProd,\n",
    "                   'arrErrMin':arrErrMin,'arrErrMax':arrErrMax}\n",
    "#     pickle_file = {'Dataset':cv_file,'mean_sum':mean_sum,'variance_sum':variance_sum,\n",
    "#                    'mean_product':mean_product,'variance_product':variance_product,\n",
    "#                   'mean_min':mean_min,'variance_min':variance_min,\n",
    "#                   'mean_max':mean_max,'variance_max':variance_max}\n",
    "    print(pickle_file)\n",
    "    pickle_out = open(\"dict_{}.pickle\".format(cv_file),\"wb\")\n",
    "    pickle.dump(pickle_file, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dataset': 'cv_australian.mat', 'arrErrSum': [0.14492753623188406, 0.3188405797101449, 0.18840579710144928, 0.17391304347826086, 0.17391304347826086, 0.18840579710144928, 0.2898550724637681, 0.15942028985507245, 0.15942028985507245, 0.2318840579710145, 0.17391304347826086, 0.2753623188405797, 0.21739130434782608, 0.2318840579710145, 0.2608695652173913, 0.2463768115942029, 0.21739130434782608, 0.2463768115942029, 0.17391304347826086, 0.18840579710144928, 0.17391304347826086, 0.2608695652173913, 0.2463768115942029, 0.17391304347826086, 0.18840579710144928, 0.21739130434782608, 0.15942028985507245, 0.21739130434782608, 0.2318840579710145, 0.2028985507246377], 'arrErrProd': [0.14492753623188406, 0.3188405797101449, 0.18840579710144928, 0.17391304347826086, 0.18840579710144928, 0.18840579710144928, 0.2898550724637681, 0.15942028985507245, 0.17391304347826086, 0.2318840579710145, 0.17391304347826086, 0.30434782608695654, 0.21739130434782608, 0.2463768115942029, 0.2608695652173913, 0.2463768115942029, 0.21739130434782608, 0.2463768115942029, 0.17391304347826086, 0.18840579710144928, 0.17391304347826086, 0.2608695652173913, 0.2463768115942029, 0.2028985507246377, 0.18840579710144928, 0.21739130434782608, 0.15942028985507245, 0.2318840579710145, 0.2318840579710145, 0.2028985507246377], 'arrErrMin': [0.15942028985507245, 0.3188405797101449, 0.2028985507246377, 0.17391304347826086, 0.18840579710144928, 0.18840579710144928, 0.30434782608695654, 0.17391304347826086, 0.17391304347826086, 0.2318840579710145, 0.17391304347826086, 0.30434782608695654, 0.21739130434782608, 0.2608695652173913, 0.2608695652173913, 0.2318840579710145, 0.2318840579710145, 0.2463768115942029, 0.18840579710144928, 0.18840579710144928, 0.15942028985507245, 0.2753623188405797, 0.2898550724637681, 0.2028985507246377, 0.17391304347826086, 0.21739130434782608, 0.14492753623188406, 0.2318840579710145, 0.2318840579710145, 0.2028985507246377], 'arrErrMax': [0.15942028985507245, 0.3188405797101449, 0.2028985507246377, 0.17391304347826086, 0.18840579710144928, 0.18840579710144928, 0.30434782608695654, 0.17391304347826086, 0.17391304347826086, 0.2318840579710145, 0.17391304347826086, 0.30434782608695654, 0.21739130434782608, 0.2608695652173913, 0.2608695652173913, 0.2318840579710145, 0.2318840579710145, 0.2463768115942029, 0.18840579710144928, 0.18840579710144928, 0.15942028985507245, 0.2753623188405797, 0.2898550724637681, 0.2028985507246377, 0.17391304347826086, 0.21739130434782608, 0.14492753623188406, 0.2318840579710145, 0.2318840579710145, 0.2028985507246377]}\n",
      "{'Dataset': 'cv_bupa.mat', 'arrErrSum': [0.38235294117647056, 0.37142857142857144, 0.34285714285714286, 0.4, 0.3142857142857143, 0.17142857142857143, 0.2647058823529412, 0.35294117647058826, 0.20588235294117646, 0.20588235294117646, 0.23529411764705882, 0.3142857142857143, 0.17142857142857143, 0.37142857142857144, 0.2857142857142857, 0.2571428571428571, 0.38235294117647056, 0.20588235294117646, 0.29411764705882354, 0.35294117647058826, 0.35294117647058826, 0.22857142857142856, 0.2857142857142857, 0.4, 0.2857142857142857, 0.3142857142857143, 0.29411764705882354, 0.2647058823529412, 0.3235294117647059, 0.29411764705882354], 'arrErrProd': [0.38235294117647056, 0.37142857142857144, 0.34285714285714286, 0.4, 0.3142857142857143, 0.14285714285714285, 0.29411764705882354, 0.35294117647058826, 0.20588235294117646, 0.20588235294117646, 0.23529411764705882, 0.3142857142857143, 0.17142857142857143, 0.37142857142857144, 0.2857142857142857, 0.2571428571428571, 0.38235294117647056, 0.17647058823529413, 0.29411764705882354, 0.38235294117647056, 0.35294117647058826, 0.22857142857142856, 0.2857142857142857, 0.4, 0.2857142857142857, 0.3142857142857143, 0.29411764705882354, 0.2647058823529412, 0.3235294117647059, 0.29411764705882354], 'arrErrMin': [0.35294117647058826, 0.34285714285714286, 0.34285714285714286, 0.42857142857142855, 0.3142857142857143, 0.17142857142857143, 0.35294117647058826, 0.4117647058823529, 0.20588235294117646, 0.20588235294117646, 0.23529411764705882, 0.3142857142857143, 0.17142857142857143, 0.3142857142857143, 0.3142857142857143, 0.2857142857142857, 0.47058823529411764, 0.20588235294117646, 0.3235294117647059, 0.35294117647058826, 0.35294117647058826, 0.2571428571428571, 0.3142857142857143, 0.37142857142857144, 0.34285714285714286, 0.3142857142857143, 0.29411764705882354, 0.2647058823529412, 0.29411764705882354, 0.35294117647058826], 'arrErrMax': [0.35294117647058826, 0.34285714285714286, 0.34285714285714286, 0.42857142857142855, 0.3142857142857143, 0.17142857142857143, 0.35294117647058826, 0.4117647058823529, 0.20588235294117646, 0.20588235294117646, 0.23529411764705882, 0.3142857142857143, 0.17142857142857143, 0.3142857142857143, 0.3142857142857143, 0.2857142857142857, 0.47058823529411764, 0.20588235294117646, 0.3235294117647059, 0.35294117647058826, 0.35294117647058826, 0.2571428571428571, 0.3142857142857143, 0.37142857142857144, 0.34285714285714286, 0.3142857142857143, 0.29411764705882354, 0.2647058823529412, 0.29411764705882354, 0.35294117647058826]}\n",
      "{'Dataset': 'cv_glass.mat', 'arrErrSum': [0.5238095238095238, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.38095238095238093, 0.47619047619047616, 0.6666666666666666, 0.42857142857142855, 0.6190476190476191, 0.5714285714285714, 0.5454545454545454, 0.5, 0.5454545454545454, 0.5, 0.2857142857142857, 0.6190476190476191, 0.47619047619047616, 0.5714285714285714, 0.6666666666666666, 0.5714285714285714, 0.5454545454545454, 0.45454545454545453, 0.4090909090909091, 0.6363636363636364, 0.47619047619047616, 0.42857142857142855, 0.5714285714285714, 0.5238095238095238, 0.5238095238095238], 'arrErrProd': [0.47619047619047616, 0.5909090909090909, 0.5, 0.5, 0.5454545454545454, 0.42857142857142855, 0.5714285714285714, 0.6666666666666666, 0.42857142857142855, 0.6190476190476191, 0.5714285714285714, 0.5909090909090909, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.47619047619047616, 0.6190476190476191, 0.47619047619047616, 0.5714285714285714, 0.6666666666666666, 0.5238095238095238, 0.45454545454545453, 0.5454545454545454, 0.5, 0.5909090909090909, 0.47619047619047616, 0.5238095238095238, 0.47619047619047616, 0.5238095238095238, 0.5714285714285714], 'arrErrMin': [0.5238095238095238, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.42857142857142855, 0.47619047619047616, 0.6666666666666666, 0.42857142857142855, 0.6666666666666666, 0.5238095238095238, 0.5909090909090909, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.3333333333333333, 0.6190476190476191, 0.42857142857142855, 0.5714285714285714, 0.7619047619047619, 0.5714285714285714, 0.5, 0.45454545454545453, 0.45454545454545453, 0.5909090909090909, 0.47619047619047616, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.6190476190476191], 'arrErrMax': [0.5238095238095238, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.42857142857142855, 0.47619047619047616, 0.6666666666666666, 0.42857142857142855, 0.6666666666666666, 0.5238095238095238, 0.5909090909090909, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.3333333333333333, 0.6190476190476191, 0.42857142857142855, 0.5714285714285714, 0.7619047619047619, 0.5714285714285714, 0.5, 0.45454545454545453, 0.45454545454545453, 0.5909090909090909, 0.47619047619047616, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.6190476190476191]}\n"
     ]
    }
   ],
   "source": [
    "dataframe = []\n",
    "for i in range(len(data_dat)):\n",
    "    data = process_data_dat(data_dat[i])\n",
    "    split_train_test_by_id(data,cv_filename[i],niters=3,nfolds=10)\n",
    "    pickle_in = open(\"dict_{}.pickle\".format(cv_filename[i]),\"rb\")\n",
    "    example_dict = pickle.load(pickle_in)\n",
    "    dataframe.append(example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>arrErrSum</th>\n",
       "      <th>arrErrProd</th>\n",
       "      <th>arrErrMin</th>\n",
       "      <th>arrErrMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>[0.14492753623188406, 0.3188405797101449, 0.18...</td>\n",
       "      <td>[0.14492753623188406, 0.3188405797101449, 0.18...</td>\n",
       "      <td>[0.15942028985507245, 0.3188405797101449, 0.20...</td>\n",
       "      <td>[0.15942028985507245, 0.3188405797101449, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cv_bupa.mat</td>\n",
       "      <td>[0.38235294117647056, 0.37142857142857144, 0.3...</td>\n",
       "      <td>[0.38235294117647056, 0.37142857142857144, 0.3...</td>\n",
       "      <td>[0.35294117647058826, 0.34285714285714286, 0.3...</td>\n",
       "      <td>[0.35294117647058826, 0.34285714285714286, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cv_glass.mat</td>\n",
       "      <td>[0.5238095238095238, 0.5454545454545454, 0.454...</td>\n",
       "      <td>[0.47619047619047616, 0.5909090909090909, 0.5,...</td>\n",
       "      <td>[0.5238095238095238, 0.5454545454545454, 0.545...</td>\n",
       "      <td>[0.5238095238095238, 0.5454545454545454, 0.545...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset                                          arrErrSum  \\\n",
       "0  cv_australian.mat  [0.14492753623188406, 0.3188405797101449, 0.18...   \n",
       "1        cv_bupa.mat  [0.38235294117647056, 0.37142857142857144, 0.3...   \n",
       "2       cv_glass.mat  [0.5238095238095238, 0.5454545454545454, 0.454...   \n",
       "\n",
       "                                          arrErrProd  \\\n",
       "0  [0.14492753623188406, 0.3188405797101449, 0.18...   \n",
       "1  [0.38235294117647056, 0.37142857142857144, 0.3...   \n",
       "2  [0.47619047619047616, 0.5909090909090909, 0.5,...   \n",
       "\n",
       "                                           arrErrMin  \\\n",
       "0  [0.15942028985507245, 0.3188405797101449, 0.20...   \n",
       "1  [0.35294117647058826, 0.34285714285714286, 0.3...   \n",
       "2  [0.5238095238095238, 0.5454545454545454, 0.545...   \n",
       "\n",
       "                                           arrErrMax  \n",
       "0  [0.15942028985507245, 0.3188405797101449, 0.20...  \n",
       "1  [0.35294117647058826, 0.34285714285714286, 0.3...  \n",
       "2  [0.5238095238095238, 0.5454545454545454, 0.545...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame.from_dict(dataframe)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_rules(cv_file,arrErrSum,arrErrProd,arrErrMin,arrErrMax):\n",
    "    #Caculate mean and variance Total Sum Rule\n",
    "    mean_sum = statistics.mean(arrErrSum)\n",
    "    variance_sum = statistics.variance(arrErrSum)\n",
    "    #Caculate mean and variance Total Product Rule\n",
    "    mean_product = statistics.mean(arrErrProd)\n",
    "    variance_product = statistics.variance(arrErrProd)\n",
    "    #Caculate mean and variance Total Min Rule\n",
    "    mean_min = statistics.mean(arrErrMin)\n",
    "    variance_min = statistics.variance(arrErrMin)\n",
    "    #Caculate mean and variance Total Max Rule\n",
    "    mean_max = statistics.mean(arrErrMax)\n",
    "    variance_max = statistics.variance(arrErrMax)\n",
    "    dict_data = {'Dataset':cv_file,'mean_sum':mean_sum,'variance_sum':variance_sum,\n",
    "                   'mean_product':mean_product,'variance_product':variance_product,\n",
    "                  'mean_min':mean_min,'variance_min':variance_min,\n",
    "                  'mean_max':mean_max,'variance_max':variance_max}\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = []\n",
    "for i in range(len(cv_filename)):\n",
    "    dict_data.append(mean_rules(cv_filename[i],data['arrErrSum'][i],data['arrErrProd'][i],\n",
    "                               data['arrErrMin'][i],data['arrErrMax'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bảng 1: Classification error của các fixed combining rule\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>mean_sum</th>\n",
       "      <th>variance_sum</th>\n",
       "      <th>mean_product</th>\n",
       "      <th>variance_product</th>\n",
       "      <th>mean_min</th>\n",
       "      <th>variance_min</th>\n",
       "      <th>mean_max</th>\n",
       "      <th>variance_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.214976</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cv_bupa.mat</td>\n",
       "      <td>0.297535</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.297563</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.309216</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.309216</td>\n",
       "      <td>0.005143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cv_glass.mat</td>\n",
       "      <td>0.517244</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.526768</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.526768</td>\n",
       "      <td>0.008172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset  mean_sum  variance_sum  mean_product  variance_product  \\\n",
       "0  cv_australian.mat  0.211111      0.001893      0.214976          0.001957   \n",
       "1        cv_bupa.mat  0.297535      0.004447      0.297563          0.005045   \n",
       "2       cv_glass.mat  0.517244      0.007327      0.540404          0.004269   \n",
       "\n",
       "   mean_min  variance_min  mean_max  variance_max  \n",
       "0  0.218357      0.002244  0.218357      0.002244  \n",
       "1  0.309216      0.005143  0.309216      0.005143  \n",
       "2  0.526768      0.008172  0.526768      0.008172  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('Bảng 1: Classification error của các fixed combining rule')\n",
    "data_1 = pd.DataFrame.from_dict(dict_data)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14492753623188406,\n",
       " 0.3188405797101449,\n",
       " 0.18840579710144928,\n",
       " 0.17391304347826086,\n",
       " 0.17391304347826086,\n",
       " 0.18840579710144928,\n",
       " 0.2898550724637681,\n",
       " 0.15942028985507245,\n",
       " 0.15942028985507245,\n",
       " 0.2318840579710145,\n",
       " 0.17391304347826086,\n",
       " 0.2753623188405797,\n",
       " 0.21739130434782608,\n",
       " 0.2318840579710145,\n",
       " 0.2608695652173913,\n",
       " 0.2463768115942029,\n",
       " 0.21739130434782608,\n",
       " 0.2463768115942029,\n",
       " 0.17391304347826086,\n",
       " 0.18840579710144928,\n",
       " 0.17391304347826086,\n",
       " 0.2608695652173913,\n",
       " 0.2463768115942029,\n",
       " 0.17391304347826086,\n",
       " 0.18840579710144928,\n",
       " 0.21739130434782608,\n",
       " 0.15942028985507245,\n",
       " 0.21739130434782608,\n",
       " 0.2318840579710145,\n",
       " 0.2028985507246377]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['arrErrSum'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caculate Win, Equal, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_compare_error(array1, array2):\n",
    "#     win_result = []\n",
    "    win_result = 0\n",
    "    for i in range(len(array1)):\n",
    "#         win_result.append(1 if array1[i] < array2[i] else 0)\n",
    "        if (array1[i] < array2[i]):\n",
    "            win_result += 1\n",
    "    return win_result\n",
    "\n",
    "def equal_compare_error(array1, array2):\n",
    "    equal_result = 0\n",
    "    for i in range(len(array1)):\n",
    "        if (array1[i] == array2[i]):\n",
    "            equal_result += 1\n",
    "    return equal_result\n",
    "\n",
    "def loss_compare_error(array1, array2):\n",
    "    loss_result = 0\n",
    "    for i in range(len(array1)):\n",
    "        if (array1[i] > array2[i]):\n",
    "            loss_result += 1\n",
    "    return loss_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['arrErrSum'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "14\n",
      "{'Dataset': 'cv_australian.mat', 'win_sum_prod': 6, 'equal_sum_prod': 24, 'loss_sum_prod': 0, 'win_sum_min': 14, 'equal_sum_min': 12, 'loss_sum_min': 4, 'win_sum_max': 14, 'equal_sum_max': 12, 'loss_sum_max': 4}\n",
      "2\n",
      "11\n",
      "{'Dataset': 'cv_bupa.mat', 'win_sum_prod': 2, 'equal_sum_prod': 26, 'loss_sum_prod': 2, 'win_sum_min': 11, 'equal_sum_min': 14, 'loss_sum_min': 5, 'win_sum_max': 11, 'equal_sum_max': 14, 'loss_sum_max': 5}\n",
      "13\n",
      "9\n",
      "{'Dataset': 'cv_glass.mat', 'win_sum_prod': 13, 'equal_sum_prod': 12, 'loss_sum_prod': 5, 'win_sum_min': 9, 'equal_sum_min': 15, 'loss_sum_min': 6, 'win_sum_max': 9, 'equal_sum_max': 15, 'loss_sum_max': 6}\n"
     ]
    }
   ],
   "source": [
    "final_results = []\n",
    "for i in range(len(cv_filename)):\n",
    "    # Sum vs Product\n",
    "    win_compare_sum_prod = win_compare_error(data['arrErrSum'][i],data['arrErrProd'][i])\n",
    "    print(win_compare_sum_prod)\n",
    "    equal_compare_sum_prod = equal_compare_error(data['arrErrSum'][i],data['arrErrProd'][i])\n",
    "    loss_compare_sum_prod = loss_compare_error(data['arrErrSum'][i],data['arrErrProd'][i])\n",
    "    # Sum vs Min\n",
    "    win_compare_sum_min = win_compare_error(data['arrErrSum'][i],data['arrErrMin'][i])\n",
    "    print(win_compare_sum_min)\n",
    "    equal_compare_sum_min = equal_compare_error(data['arrErrSum'][i],data['arrErrMin'][i])\n",
    "    loss_compare_sum_min = loss_compare_error(data['arrErrSum'][i],data['arrErrMin'][i])\n",
    "    # Sum vs Max\n",
    "    win_compare_sum_max = win_compare_error(data['arrErrSum'][i],data['arrErrMax'][i])\n",
    "    equal_compare_sum_max = equal_compare_error(data['arrErrSum'][i],data['arrErrMax'][i])\n",
    "    loss_compare_sum_max = loss_compare_error(data['arrErrSum'][i],data['arrErrMax'][i])\n",
    "    dict_result = {'Dataset':cv_filename[i],'win_sum_prod':win_compare_sum_prod,'equal_sum_prod':equal_compare_sum_prod,\n",
    "                  'loss_sum_prod':loss_compare_sum_prod,'win_sum_min':win_compare_sum_min,'equal_sum_min':equal_compare_sum_min,\n",
    "                  'loss_sum_min':loss_compare_sum_min,'win_sum_max':win_compare_sum_max,'equal_sum_max':equal_compare_sum_max,\n",
    "                  'loss_sum_max':loss_compare_sum_max}\n",
    "    print(dict_result)\n",
    "    final_results.append(dict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: cv_australian.mat\n",
      "Wilcoxon Sum vs Product Rules: WilcoxonResult(statistic=0.0, pvalue=0.023140931308743732)\n",
      "Wilcoxon Sum vs Min Rules: WilcoxonResult(statistic=27.0, pvalue=0.00830538569425914)\n",
      "Wilcoxon Sum vs Max Rules: WilcoxonResult(statistic=27.0, pvalue=0.00830538569425914)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#Wilcoxon Sum vs Other Rules\n",
    "print(\"DATA: cv_australian.mat\")\n",
    "print(\"Wilcoxon Sum vs Product Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][0],data['arrErrProd'][0],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Min Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][0],data['arrErrMin'][0],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Max Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][0],data['arrErrMax'][0],zero_method='wilcox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: cv_bupa.mat\n",
      "Wilcoxon Sum vs Product Rules: WilcoxonResult(statistic=4.0, pvalue=0.7150006546880893)\n",
      "Wilcoxon Sum vs Min Rules: WilcoxonResult(statistic=39.0, pvalue=0.1322337553254543)\n",
      "Wilcoxon Sum vs Max Rules: WilcoxonResult(statistic=39.0, pvalue=0.1322337553254543)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA: cv_bupa.mat\")\n",
    "print(\"Wilcoxon Sum vs Product Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][1],data['arrErrProd'][1],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Min Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][1],data['arrErrMin'][1],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Max Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][1],data['arrErrMax'][1],zero_method='wilcox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: cv_glass.mat\n",
      "Wilcoxon Sum vs Product Rules: WilcoxonResult(statistic=45.5, pvalue=0.0811807696065937)\n",
      "Wilcoxon Sum vs Min Rules: WilcoxonResult(statistic=32.0, pvalue=0.11075675208022244)\n",
      "Wilcoxon Sum vs Max Rules: WilcoxonResult(statistic=32.0, pvalue=0.11075675208022244)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA: cv_glass.mat\")\n",
    "print(\"Wilcoxon Sum vs Product Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][2],data['arrErrProd'][2],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Min Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][2],data['arrErrMin'][2],zero_method='wilcox'))\n",
    "print(\"Wilcoxon Sum vs Max Rules:\",scipy.stats.wilcoxon(data['arrErrSum'][2],data['arrErrMax'][2],zero_method='wilcox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bảng 2: Kết quả kiểm định\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>win_sum_prod</th>\n",
       "      <th>equal_sum_prod</th>\n",
       "      <th>loss_sum_prod</th>\n",
       "      <th>win_sum_min</th>\n",
       "      <th>equal_sum_min</th>\n",
       "      <th>loss_sum_min</th>\n",
       "      <th>win_sum_max</th>\n",
       "      <th>equal_sum_max</th>\n",
       "      <th>loss_sum_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cv_australian.mat</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cv_bupa.mat</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cv_glass.mat</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset  win_sum_prod  equal_sum_prod  loss_sum_prod  \\\n",
       "0  cv_australian.mat             6              24              0   \n",
       "1        cv_bupa.mat             2              26              2   \n",
       "2       cv_glass.mat            13              12              5   \n",
       "\n",
       "   win_sum_min  equal_sum_min  loss_sum_min  win_sum_max  equal_sum_max  \\\n",
       "0           14             12             4           14             12   \n",
       "1           11             14             5           11             14   \n",
       "2            9             15             6            9             15   \n",
       "\n",
       "   loss_sum_max  \n",
       "0             4  \n",
       "1             5  \n",
       "2             6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('Bảng 2: Kết quả kiểm định')\n",
    "data_2 = pd.DataFrame.from_dict(final_results)\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
