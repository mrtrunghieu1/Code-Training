{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preapre Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_austradian = [i.strip().split() for i in open(\"australian_train1.dat\").readlines()] \n",
    "data_test_austradian = [i.strip().split() for i in open(\"australian_test.dat\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature(observe):\n",
    "    res = ast.literal_eval(observe[0])\n",
    "    feature_observe = list(res)[:len(observe) - 2]\n",
    "    label_observe = list(res)[-1]\n",
    "    return feature_observe,label_observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 14)\n",
      "(207,)\n"
     ]
    }
   ],
   "source": [
    "labels_train = []\n",
    "features_train = []\n",
    "for i, sample in enumerate(data_train_austradian):\n",
    "    feature_train_sample, label_train_sample = process_feature(sample)\n",
    "    features_train.append(feature_train_sample)\n",
    "    labels_train.append(label_train_sample)\n",
    "# Covert to array\n",
    "features_train = np.asarray(features_train)    #Shape matrix 386 * 14\n",
    "labels_train = np.asarray(labels_train)        #Shape matrix 386 * 1\n",
    "\n",
    "# Process Test Data\n",
    "features_test = []\n",
    "labels_test = []\n",
    "for i, sample in enumerate(data_test_austradian):\n",
    "    feature_test_sample, label_test_data = process_feature(sample)\n",
    "    features_test.append(feature_test_sample)\n",
    "    labels_test.append(label_test_data)\n",
    "#Covert to array\n",
    "features_test = np.asarray(features_test)      #Shape matrix 207 * 14\n",
    "labels_test = np.asarray(labels_test)          #Shape matrix 207 * 1\n",
    "print(features_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN,Naive Bayes,LogisticRegression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithms\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)\n",
    "clf.fit(features_train,labels_train)\n",
    "label_predict_knn_prob = clf.predict_proba(features_test)# probability in class\n",
    "label_predict_knn = clf.predict(features_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train,labels_train)\n",
    "label_predict_gnb = gnb.predict(features_test)\n",
    "label_predict_gnb_prob = gnb.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression algorithms\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(features_train,labels_train)\n",
    "label_predict_lr = clf.predict(features_test)\n",
    "label_predict_lr_prob = clf.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation K Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(observe):\n",
    "    res = ast.literal_eval(observe[0])\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "austradian = []\n",
    "for sample in data_train_austradian:\n",
    "    austradian.append(process_dataset(sample))\n",
    "austradian = np.asarray(austradian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ LogisticRegression(random_state=0),GaussianNB(),\n",
    "          neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 5.783e+03, 7.040e+02, ..., 2.000e+00, 3.600e+02,\n",
       "        1.333e+03],\n",
       "       [0.000e+00, 5.575e+03, 7.080e+02, ..., 2.000e+00, 1.000e+02,\n",
       "        5.100e+01],\n",
       "       [1.000e+00, 4.483e+03, 7.000e+00, ..., 2.000e+00, 1.600e+02,\n",
       "        3.000e+00],\n",
       "       ...,\n",
       "       [0.000e+00, 2.975e+03, 6.650e+02, ..., 2.000e+00, 3.000e+02,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 2.858e+03, 3.750e+02, ..., 2.000e+00, 4.000e+01,\n",
       "        1.550e+02],\n",
       "       [1.000e+00, 4.100e+01, 4.000e+00, ..., 1.000e+00, 5.600e+02,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables to store metadata and target\n",
    "meta_data = np.zeros((len(models) * 2,len(features_train)))\n",
    "meta_targets = np.zeros(len(features_train))\n",
    "\n",
    "#Create the cross-validation folds\n",
    "KF = KFold(n_splits=10)\n",
    "meta_index = 0\n",
    "for train_indices, test_indices in KF.split(features_train):\n",
    "    for i in range(len(models)):\n",
    "        learner = models[i]\n",
    "        learner.fit(features_train[train_indices], labels_train[train_indices])\n",
    "        predictions = learner.predict_proba(features_train[test_indices])\n",
    "        meta_data[2*i][meta_index:meta_index + len(test_indices)] = predictions.T[0]\n",
    "        meta_data[2*i + 1][meta_index:meta_index + len(test_indices)] = predictions.T[1]\n",
    "    meta_targets[meta_index:meta_index + len(test_indices)] = labels_train[test_indices]\n",
    "    meta_index += len(test_indices)\n",
    "#Transpose the metadata\n",
    "meta_data = meta_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(meta_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 6.5420e+03, 1.1000e+01, ..., 2.0000e+00, 2.2000e+01,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 1.8170e+03, 1.0250e+03, ..., 2.0000e+00, 3.2000e+02,\n",
       "        1.4000e+01],\n",
       "       [1.0000e+00, 4.8500e+02, 4.2500e+02, ..., 2.0000e+00, 2.2500e+02,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 4.1420e+03, 5.0000e+00, ..., 2.0000e+00, 4.7000e+02,\n",
       "        1.0000e+00],\n",
       "       [0.0000e+00, 2.5750e+03, 5.0000e+00, ..., 2.0000e+00, 4.9100e+02,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 4.7670e+03, 2.9000e+01, ..., 2.0000e+00, 0.0000e+00,\n",
       "        1.5001e+04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(models, train_set, label_set, validation_set):\n",
    "    result_list = []\n",
    "    for model in models:\n",
    "        clf = model \n",
    "        clf.fit(train_set,label_set) \n",
    "        result = clf.predict_proba(validation_set)\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = model(models=models,train_set=features_train,label_set=labels_train,validation_set = features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = np.concatenate((result_list[0],result_list[1],result_list[2]),axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preict = clf.predict(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.81      0.70      0.75        81\n",
      "     class 2       0.82      0.90      0.86       126\n",
      "\n",
      "    accuracy                           0.82       207\n",
      "   macro avg       0.82      0.80      0.81       207\n",
      "weighted avg       0.82      0.82      0.82       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 1','class 2']\n",
    "print(classification_report(labels_test, label_preict, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
