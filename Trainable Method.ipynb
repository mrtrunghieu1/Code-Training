{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preapre Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_austradian = [i.strip().split() for i in open(\"australian_train1.dat\").readlines()] \n",
    "data_test_austradian = [i.strip().split() for i in open(\"australian_test.dat\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature(observe):\n",
    "    res = ast.literal_eval(observe[0])\n",
    "    feature_observe = list(res)[:len(observe) - 2]\n",
    "    label_observe = list(res)[-1]\n",
    "    return feature_observe,label_observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of Train: (386, 14)\n",
      "Labels of Train: (386,)\n",
      "Features of Test: (207, 14)\n",
      "Labels of Test: (207,)\n"
     ]
    }
   ],
   "source": [
    "labels_train = []\n",
    "features_train = []\n",
    "for i, sample in enumerate(data_train_austradian):\n",
    "    feature_train_sample, label_train_sample = process_feature(sample)\n",
    "    features_train.append(feature_train_sample)\n",
    "    labels_train.append(label_train_sample)\n",
    "# Covert to array\n",
    "features_train = np.asarray(features_train)    #Shape matrix 386 * 14\n",
    "print(\"Features of Train:\",features_train.shape)\n",
    "labels_train = np.asarray(labels_train)        #Shape matrix 386 * 1\n",
    "print(\"Labels of Train:\",labels_train.shape)\n",
    "# Process Test Data\n",
    "features_test = []\n",
    "labels_test = []\n",
    "for i, sample in enumerate(data_test_austradian):\n",
    "    feature_test_sample, label_test_data = process_feature(sample)\n",
    "    features_test.append(feature_test_sample)\n",
    "    labels_test.append(label_test_data)\n",
    "#Covert to array\n",
    "features_test = np.asarray(features_test)      #Shape matrix 207 * 14\n",
    "print(\"Features of Test:\",features_test.shape)\n",
    "labels_test = np.asarray(labels_test)          #Shape matrix 207 * 1\n",
    "print(\"Labels of Test:\",labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN,Naive Bayes,LogisticRegression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithms\n",
    "clf_knn = neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)\n",
    "clf_knn.fit(features_train,labels_train)\n",
    "label_predict_knn_prob = clf_knn.predict_proba(features_test)# probability in class\n",
    "label_predict_knn = clf_knn.predict(features_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(features_train,labels_train)\n",
    "label_predict_gnb = clf_gnb.predict(features_test)\n",
    "label_predict_gnb_prob = clf_gnb.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression algorithms\n",
    "clf_lr = LogisticRegression(random_state=0)\n",
    "clf_lr.fit(features_train,labels_train)\n",
    "label_predict_lr = clf_lr.predict(features_test)\n",
    "label_predict_lr_prob = clf_lr.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation K Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(observe):\n",
    "    res = ast.literal_eval(observe[0])\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data train =  features + label: (386, 15)\n"
     ]
    }
   ],
   "source": [
    "austradian = []\n",
    "for sample in data_train_austradian:\n",
    "    austradian.append(process_dataset(sample))\n",
    "austradian = np.asarray(austradian)\n",
    "print(\"Data train =  features + label:\",austradian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                      weights='uniform')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [ LogisticRegression(random_state=0),GaussianNB(),neighbors.KNeighborsClassifier(n_neighbors=10,p = 2)]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Create variables to store metadata ===================\n",
      "meta data features: (6, 386)\n",
      "meta data labels: (386,)\n",
      "========== Create the cross-validation folds ====================\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (347, 14)\n",
      "Size test: (39, 14)\n",
      "Size train: (348, 14)\n",
      "Size test: (38, 14)\n",
      "Size train: (348, 14)\n",
      "Size test: (38, 14)\n",
      "Size train: (348, 14)\n",
      "Size test: (38, 14)\n",
      "Size train: (348, 14)\n",
      "Size test: (38, 14)\n",
      "Meta data: (386, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store metadata and target\n",
    "print(\"========== Create variables to store metadata ===================\")\n",
    "meta_data = np.zeros((len(models) * 2,len(features_train)))\n",
    "print(\"meta data features:\", meta_data.shape)\n",
    "meta_targets = np.zeros(len(features_train))\n",
    "print(\"meta data labels:\", meta_targets.shape)\n",
    "#Create the cross-validation folds\n",
    "print(\"========== Create the cross-validation folds ====================\")\n",
    "KF = KFold(n_splits=10)\n",
    "meta_index = 0\n",
    "for train_indices, test_indices in KF.split(features_train):\n",
    "    print(\"Size train:\",features_train[train_indices].shape)\n",
    "    print(\"Size test:\",features_train[test_indices].shape)\n",
    "    for i in range(len(models)):\n",
    "        learner = models[i]\n",
    "        learner.fit(features_train[train_indices], labels_train[train_indices])\n",
    "        predictions = learner.predict_proba(features_train[test_indices])\n",
    "        meta_data[2*i][meta_index:meta_index + len(test_indices)] = predictions.T[0]\n",
    "        meta_data[2*i + 1][meta_index:meta_index + len(test_indices)] = predictions.T[1]\n",
    "    meta_targets[meta_index:meta_index + len(test_indices)] = labels_train[test_indices]\n",
    "    meta_index += len(test_indices)\n",
    "#Transpose the metadata\n",
    "meta_data = meta_data.transpose()\n",
    "print(\"Meta data:\",meta_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(meta_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 6.5420e+03, 1.1000e+01, ..., 2.0000e+00, 2.2000e+01,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 1.8170e+03, 1.0250e+03, ..., 2.0000e+00, 3.2000e+02,\n",
       "        1.4000e+01],\n",
       "       [1.0000e+00, 4.8500e+02, 4.2500e+02, ..., 2.0000e+00, 2.2500e+02,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 4.1420e+03, 5.0000e+00, ..., 2.0000e+00, 4.7000e+02,\n",
       "        1.0000e+00],\n",
       "       [0.0000e+00, 2.5750e+03, 5.0000e+00, ..., 2.0000e+00, 4.9100e+02,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 4.7670e+03, 2.9000e+01, ..., 2.0000e+00, 0.0000e+00,\n",
       "        1.5001e+04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combining_test_matrix = np.concatenate((label_predict_knn_prob,label_predict_gnb_prob,label_predict_lr_prob),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def model(models, train_set, label_set, validation_set):\n",
    "    result_list = []\n",
    "    for model in models:\n",
    "        clf = model \n",
    "        clf.fit(train_set,label_set) \n",
    "        result = clf.predict_proba(validation_set)\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result_list = model(models=models,train_set=features_train,label_set=labels_train,validation_set = features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preict = clf_svm.predict(combining_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.80      0.65      0.72        81\n",
      "     class 2       0.80      0.90      0.85       126\n",
      "\n",
      "    accuracy                           0.80       207\n",
      "   macro avg       0.80      0.78      0.78       207\n",
      "weighted avg       0.80      0.80      0.80       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 1','class 2']\n",
    "print(classification_report(labels_test, label_preict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
